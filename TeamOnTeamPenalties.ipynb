{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary of team names and abbreviations. VEG is used instead of VGK.\n",
    "teamAbvs = {'Anaheim Ducks':'ANA', 'Arizona Coyotes':'ARI', 'Atlanta Thrashers': 'ATL', 'Boston Bruins': 'BOS', 'Buffalo Sabres':'BUF', 'Carolina Hurricanes':'CAR',\n",
    "            'Calgary Flames':'CGY', 'Chicago Blackhawks':'CHI', 'Columbus Blue Jackets':'CBJ', 'Colorado Avalanche':'COL', 'Dallas Stars':'DAL',\n",
    "           'Detroit Red Wings':'DET', 'Edmonton Oilers':'EDM', 'Florida Panthers':'FLA', 'Los Angeles Kings':'LAK',\n",
    "           'Minnesota Wild':'MIN', 'Montreal Canadiens':'MTL', 'Nashville Predators':'NSH', 'New Jersey Devils':'NJD',\n",
    "           'New York Islanders':'NYI', 'New York Rangers':'NYR', 'Ottawa Senators':'OTT', 'Phoenix Coyotes':'PHX', 'Philadelphia Flyers':'PHI',\n",
    "           'Pittsburgh Penguins':'PIT', 'San Jose Sharks':'SJS', 'St. Louis Blues':'STL', 'Tampa Bay Lightning':'TBL',\n",
    "           'Toronto Maple Leafs':'TOR','Vancouver Canucks':'VAN', 'Vegas Golden Knights':'VEG', 'Washington Capitals':'WSH', 'Winnipeg Jets':'WPG',\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to produce the table for each season\n",
    "def startSeason(season_url):\n",
    "    season_year = season_url.split('_')[1]\n",
    "    \n",
    "    #Retrieving the initial url and HTML.\n",
    "    try:\n",
    "        season_page = urlopen(season_url)\n",
    "    except urllib.error.URLError:\n",
    "        return print('Error with URL')\n",
    "        \n",
    "    season_soup = BeautifulSoup(season_page, 'lxml')\n",
    "    \n",
    "    #Building the schedule table.\n",
    "    season_games = season_soup.find(id='games')\n",
    "    Date =[]\n",
    "    Vis=[]\n",
    "    VG=[]\n",
    "    Home=[]\n",
    "    HG=[]\n",
    "    OT=[]\n",
    "    Att=[]\n",
    "    LOG=[]\n",
    "    Notes=[]\n",
    "\n",
    "    #Create a table with a list for each column of data.\n",
    "    headers = [Date, Vis, VG, Home, HG, OT, Att, LOG, Notes]\n",
    "    \n",
    "    #Iterate through each row and column, assigning the corresponding data to the location in 'headers'.\n",
    "    for row in season_games.findAll('tr'):\n",
    "        cells = row.findAll(['td','th'])\n",
    "        index = np.arange(0,len(cells)).tolist()\n",
    "        for num in index:\n",
    "            headers[num].append(cells[num].find(text=True))\n",
    "            \n",
    "    #Create the games Dataframe, set the column names to names instead of index values.\n",
    "    season_gamesDf = pd.DataFrame(headers).transpose()\n",
    "    season_gamesDf.columns = season_gamesDf.iloc[0]\n",
    "    season_gamesDf = season_gamesDf.reindex(season_gamesDf.index.drop(0))\n",
    "    \n",
    "    #Create game HTML string for every game.\n",
    "    gameHTML = []\n",
    "    for entry in season_gamesDf.index:\n",
    "        abv = teamAbvs[season_gamesDf['Home'][entry]]\n",
    "        daystr = ''.join(season_gamesDf['Date'][entry].split('-'))\n",
    "        gamestr = (daystr+'0'+abv)\n",
    "        gamepage = ('https://www.hockey-reference.com/boxscores/'+gamestr+'.html')\n",
    "        gameHTML.append(gamepage)\n",
    "    #Add the new gameHTML column to gamesDf.\n",
    "    season_gamesDf['Game HTML'] = gameHTML\n",
    "    \n",
    "    #Remove any cancelled games\n",
    "    season_gamesDf['Date'] = pd.to_datetime(season_gamesDf['Date'], infer_datetime_format=True)\n",
    "    cancelledDf = season_gamesDf[(season_gamesDf['Att.'].isna() == True) & (season_gamesDf['Date'] < datetime.now())]\n",
    "    cancelled_games = cancelledDf.index.tolist()\n",
    "    season_gamesDf = season_gamesDf.reindex(season_gamesDf.index.drop(cancelled_games))\n",
    "    \n",
    "    return season_gamesDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to build team dfs for the season\n",
    "teams = sorted(list(teamAbvs.values()))\n",
    "all_teams = sorted(list(teamAbvs.values()))\n",
    "#Need ATL and PHX in the dictionary for the HTML retrieval, do not want separate DFs for them.\n",
    "teams.remove('ATL')\n",
    "teams.remove('PHX')\n",
    "\n",
    "#Column names\n",
    "table_columns = ['otherteam', 'homegames', 'awaygames', 'ngames', 'homepenalties', 'awaypenalties', 'totalpenalties', 'normalizedpenalties']\n",
    "\n",
    "#Dictionary with team dfs\n",
    "teams_dict = dict.fromkeys(teams)\n",
    "\n",
    "#Initial DF data creation\n",
    "emptydata = np.zeros(len(teams)).tolist()\n",
    "for t in teams:\n",
    "    edf_data = dict.fromkeys(table_columns)\n",
    "    edf_data['otherteam'] = teams\n",
    "    for c in table_columns[1:]:\n",
    "        edf_data[c] = emptydata\n",
    "    df = pd.DataFrame(edf_data)\n",
    "    teams_dict[t] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n"
     ]
    }
   ],
   "source": [
    "#Now need to open each page in the season_gamesDf\n",
    "season_page = startSeason('https://www.hockey-reference.com/leagues/NHL_2018_games.html')\n",
    "for num in season_page.index.tolist()[1156:]:\n",
    "    #Open the page for a game\n",
    "    gamepage = season_page['Game HTML'][num]\n",
    "    try:\n",
    "        openedgame = urlopen(gamepage)\n",
    "    except urllib.error.URLError:\n",
    "        print('Error with URL')\n",
    "    #Gather the html and the penalty table\n",
    "    gamesoup = BeautifulSoup(openedgame, 'lxml')    \n",
    "    penaltytable = gamesoup.find(id='penalty')\n",
    "    #Initialize necessary variables for each game\n",
    "    hometeam = teamAbvs[season_page['Home'][num]]\n",
    "    visitorteam = teamAbvs[season_page['Visitor'][num]]\n",
    "    homepenalties = 0\n",
    "    visitorpenalties = 0\n",
    "    #Parse the penalties and record which team took penalties\n",
    "    for row in penaltytable.findAll('tr'):\n",
    "        rowtext = row.get_text().upper().split()\n",
    "        penalizedteam = [name for name in rowtext if name in all_teams]\n",
    "        name = ''\n",
    "        if len(penalizedteam) > 0:\n",
    "            name = penalizedteam[0]\n",
    "            if name == 'PHX':\n",
    "                name = 'ARI'\n",
    "            if name == 'ATL':\n",
    "                name = 'WPG'\n",
    "        if name == hometeam:\n",
    "            homepenalties += 1\n",
    "        if name == visitorteam:\n",
    "            visitorpenalties += 1\n",
    "    #Add the new data to the homes table\n",
    "    homedf = teams_dict[hometeam]\n",
    "    indexvis = homedf[homedf['otherteam']==visitorteam].index[0]\n",
    "    homedf.at[indexvis, 'homegames'] += 1\n",
    "    homedf.at[indexvis, 'homepenalties'] += homepenalties\n",
    "    \n",
    "    #Add the new data to the visitors table\n",
    "    visdf = teams_dict[visitorteam]\n",
    "    indexhome = visdf[visdf['otherteam']==hometeam].index[0]\n",
    "    visdf.at[indexhome, 'awaygames'] += 1\n",
    "    visdf.at[indexhome, 'awaypenalties'] += visitorpenalties\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Save all tables to their own csv file for importing into SQL database\n",
    "for t in teams:\n",
    "    tdf = teams_dict[t]\n",
    "    tdf['ngames'] = tdf['homegames']+tdf['awaygames']\n",
    "    tdf['totalpenalties'] = tdf['homepenalties']+tdf['awaypenalties']\n",
    "    tdf['normalizedpenalties'] = tdf['totalpenalties']/tdf['ngames']\n",
    "    tdf['normalizedhomepenalties'] = tdf['homepenalties']/tdf['homegames']\n",
    "    tdf['normalizedawaypenalties'] = tdf['awaypenalties']/tdf['awaygames']\n",
    "    #tdf.to_csv(t+'_penalties_20172018', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
